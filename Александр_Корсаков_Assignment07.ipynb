{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"Александр_Корсаков_Assignment07.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"xJPDrYoTp4Eb","colab_type":"text"},"source":["## Задание 07"]},{"cell_type":"markdown","metadata":{"id":"VDIUBSclp4Eh","colab_type":"text"},"source":["### Задача 1. Смещение константного алгоритма (2 балла)\n","Пусть $x \\in R^d$, и значение каждого признака на объекте $x$ независимо генерируется из равномерного распределения $x_i\\in U[0,1],i=1,2\\dots,d$. Будем считать, что объекты в выборке независимы, а $\\mathbb{E}[y|x]=x^Tx.$ Найдите смещение константного алгоритма, полученного минимизацией среднеквадратичной ошибки на обучающей выборке. "]},{"cell_type":"markdown","metadata":{"id":"uMMcHixtJptA","colab_type":"text"},"source":["$\\DeclareMathOperator{\\E}{\\mathbb{E}}$\n","$\\DeclareMathOperator{\\X}{\\mathbb{X}}$\n","\n","Разложение ошибки для задачи регрессии с выборкой $\\X^l$ и среднеквадратичной ошибкой.\n","\n","$$\n","  L(\\nu) = \\E_{x,y}[(y-\\E[y|x])^2]+\\E_{x,y}[(\\E_{X^l}[\\nu(\\X^l)(x)]-\\E[y|x])^2]+\\E_{x,y}[\\E_{X^l}[(\\nu(\\X^l)(x)-\\E_{\\X^l}[\\nu(\\X^l)(x)])^2]]\n","$$\n","\n","\\\n","\n","Для начала, чтобы найти смещениеб необходимо найти мат.ожидание по всем выборкам для константы полученной путём минимизации квадратичной ошибки.  \n","\n","\\\n","\n","Найдем средний по всем выборкам ответ алгоритма на объекте $x$:\n","\n","\\\n","\n","$$\n","  \\E_{X^l}[\\nu(\\X^l)(x)] = \\E[\\frac{\\sum_{i=1}^l y_i}{l}]=\\frac{\\sum_{i=1}^l \\E[y_i]}{l}=\\{\\E(\\E(y|x))=\\E(y)\\}=\\E(x^Tx)=\\int_0^1[ \\dots \\int_0^1(\\sum_{i=1}^d x_i^2 )dx_1dx_2 \\dots ]dx_d=\\frac{d}{3}\n","$$\n","\n","\\\n","\n","Тогда выражение для смещения перепишется в следующем виде:\n","\n","$$\n","  \\E_{x,y}[(\\E_{X^l}[\\nu(\\X^l)(x)]-\\E[y|x])^2] = \\E_{x,y}[(\\frac{d}{3}-\\sum_{i=1}^d x_i^2)^2]=\\\\\n","  =\\int_0^1[ \\dots \\int_0^1(\\frac{d^2}{9}-\\frac{2d}{3}\\cdot \\sum_{i=1}^d x_i^2+\\sum_{i=1}^d x_i^4+d \\cdot (d-1)\\sum_{i \\neq j}x_i^2x_j^2)dx_1dx_2 \\dots ]dx_d=\\\\\n","  =\\frac{d^2}{9}-\\frac{2d}{3} \\cdot \\frac{d}{3}+\\frac{d}{5}+d\\cdot (d-1)\\cdot \\frac{1}{9}=-\\frac{d^2}{9}+\\frac{d}{5}+\\frac{d^2}{9}-\\frac{d}{9}=\\frac{4d}{45}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"VrhwNA0Up4Eu","colab_type":"text"},"source":["### Задача 2. Разложение ошибки (2 балла)\n","Истинная зависимость имеет вид $y_i = 3x^2_i+ u_i$, где $y_i$ - прогнозируемая переменная, $x_i$-признак и $u_i$ - случайная составляющая. Величины $x_i$ независимы и равновероятно принимаю значения $0, 1, 2$. Величины $u_i$ независимы и равновероятно принимают значения $−1$ и $1$.\n","Исследователь Анатолий оценивает модель линейной регрессии $y_i = wx_i$, минимизируя среднеквадратичную ошибку.\n","Разложите ожидание квадрата ошибки прогноза на шум, смещение и разброс."]},{"cell_type":"markdown","metadata":{"id":"g2rSON3NBA-F","colab_type":"text"},"source":["Разложение ошибки для задачи регрессии с выборкой $\\X^l$ и среднеквадратичной ошибкой.\n","\n","$$\n","  L(\\nu) = \\E_{x,y}[(y-\\E[y|x])^2]+\\E_{x,y}[(\\E_{X^l}[\\nu(\\X^l)(x)]-\\E[y|x])^2]+\\E_{x,y}[\\E_{X^l}[(\\nu(\\X^l)(x)-\\E_{\\X^l}[\\nu(\\X^l)(x)])^2]]\n","$$\n","\n","\n","#### 1. Найдём значение шума:\n","\n","$$\n","  \\E_{x,y,u}[(y-\\E[y|x])^2] = \\E_{x,y,u}[(3x^2+u-\\E[3x^2+u|x])^2]=\\E_u[u^2]=\\sigma^2(u)=\\{ \\E[x^2]-\\E^2[x]=1-(0.5*1-0.5*1)\\}=1\n","$$\n","\n","\\\n","\n","#### 2.Найдем средний по всем выборкам ответ алгоритма на объекте $x$:\n","\n","$$\n","  L(y,w,x)=\\frac{1}{l}\\cdot \\sum_{i=1}^l(y_i-w\\cdot x_i)^2 \\rightarrow min\\\\\n","  \\frac{\\partial L}{\\partial w} =  \\sum_{i=1}^l (y_i\\cdot x_i-w\\cdot x_i^2)=0\\\\\n","  w=\\frac{\\sum_{i=1}^l y_i\\cdot x_i}{\\sum_{i=1}^l x_i^2}\n","$$\n","\n","\\\n","\n","$$\n","  \\E_{X^l}[\\nu(\\X^l)(x)]=\\E_{X^l}[w(\\X^l)]\\cdot x\\\\\n","  \\E_{X^l}[w(\\X^l)]=\\E[\\frac{\\sum_{i=1}^l y_i\\cdot x_i}{\\sum_{i=1}^l x_i^2}]=\\E[\\frac{\\sum_{i=1}^l (3x_i^2+u_i)\\cdot x_i}{\\sum_{i=1}^l x_i^2}]=\\E[\\frac{\\sum_{i=1}^l (3x_i^3)}{\\sum_{i=1}^l x_i^2}]+\\E[\\frac{\\sum_{i=1}^l u_i\\cdot x_i}{\\sum_{i=1}^{l}x_i^2}] \\;(*)\\\\\n","  \\E[\\frac{\\sum_{i=1}^l u_i\\cdot x_i}{\\sum_{i=1}^{l}x_i^2}] = \\E[\\frac{<u,x>}{<x,x>}]=\\E[<u,\\frac{x}{<x,x>}>]=\\{из\\;независимости\\; и\\; некоррелированности\\}=\\\\\n","  =<\\E[u],\\E[\\frac{x}{<x,x>}]>=0\n","$$\n","\n","$$\n","  (*)=3\\cdot\\sum_{i=1}^l(\\E[\\frac{x_i^3}{\\sum_{i=1}^l x_i^2}])\n","$$\n","\n","Проверим выражение под знаком мат.ожидания на коррелированность:\n","\n","\\\n","\n","$$\n","  Corr(x^3, \\sum_{i=1}^lx_i^2)=\\frac{\\E[x^3*\\sum_{i=1}^lx_i^2]-\\E{[x^3]}\\E{[\\sum_{i=1}^lx_i^2]}}{\\sqrt{Var{[x^3]}\\cdot Var{[\\sum_{i=1}^lx_i^2]}}}=\\frac{45/9*l-45/9*l}{\\sqrt{Var{[x^3]}\\cdot Var{[\\sum_{i=1}^lx_i^2]}}}=0\n","$$\n","\n","\\\n","\n","Поэтому можем переписать выражение (*) следующим образом:\n","\n","\\\n","\n","$$\n","  (*)=3\\cdot\\sum_{i=1}^l\\frac{\\E[x^3]}{\\E[\\sum_{i=1}^l(x_i^2)]}=3l\\cdot\\frac{9/3}{5/3*l}=\\frac{27}{5}\n","$$\n","\n","\\\n","\n","Теперь можем расчитать смещение:\n","\n","$$\n","  \\E_{x,y,u}[(\\frac{27}{5}x-3x^2)^2]=\\E_x[(\\frac{27}{5}x)^2-\\frac{6*27x^3}{5}+9x^4]=(\\frac{27}{5})^2*(\\frac{5}{3})^2-\\frac{162}{5}\\E[x^3]+9*\\E[x^4]=\\\\\n","  = 81-\\frac{162}{5}*3+9*(\\frac{17}{3})=34.8\n","$$\n","\n","/\n","\n","Перейдём к вычислению разброса:\n","\n","$$\n","  \\E_{x,y}[\\E_{X^l}[(\\nu(\\X^l)(x)-\\E_{\\X^l}[\\nu(\\X^l)(x)])^2]]\\\\\n","  \\E_{X^l}[(\\nu(\\X^l)(x)-\\E_{\\X^l}[\\nu(\\X^l)(x)])^2]=\\E_{X^l}[(\\frac{\\sum_{i=1}^l y_i\\cdot x_i}{\\sum_{i=1}^l x_i^2}\\cdot x-\\frac{27*x}{5})^2=\\\\\n","  =E_{X^l}[(\\frac{\\sum_{i=1}^l y_i\\cdot x_i}{\\sum_{i=1}^l x_i^2})^2]-2*27*x^2/5*\\E_{X^l}[\\frac{\\sum_{i=1}^l y_i\\cdot x_i}{\\sum_{i=1}^l x_i^2}]+(\\frac{27x}{5})^2=\\\\\n","  =E_{X^l}[(\\frac{\\sum_{i=1}^l y_i\\cdot x_i}{\\sum_{i=1}^l x_i^2})^2]*x^2-27^2*x^2/5^2\n","$$\n","\n","Рассмотрим первый член выражения без $x^2$:\n","\n","$$\n","  E_{X^l}[(\\frac{\\sum_{i=1}^l y_i\\cdot x_i}{\\sum_{i=1}^l x_i^2})^2]=E_{X^l}[\\frac{ \\sum_{i=1}^l x_i^2*y_i^2+2*\\sum_{i<j}x_i*x_j*y_i*y_j }{ \\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2 }]=\\\\\n","  = \\sum_{i=1}^l E_{X^l}[\\frac{  x_i^2*y_i^2}{\\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2}]+2*\\sum_{i<j}E_{X^l}[\\frac{x_i*x_j*y_i*y_j }{\\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2}]\n","$$\n","\n","\\\n","\n","ПОкажем, что числители в обеих дробях не коррелируют со знаменателями\n","\n","$$\n","  Corr(x_i^2*y_i^2,  \\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2)=\\\\\n","  =\\frac{\\E[x_i^2*y_i^2*( \\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2 )]-\\E{[x_i^2*y_i^2]}\\E{[\\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2]}}{\\sqrt{Var{[x_i^2*y_i^2]}\\cdot Var{[\\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2]}}}=\\\\\n","  =\\frac{17l*1180/18+l(l-1)*1180*8/36-1180/6*(17*l/3+l(l-1)*8/6)}{\\sqrt{Var{[x_i^2*y_i^2]}\\cdot Var{[\\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2]}}}=0\n","$$\n","\n","\\\n","\n","$$\n","   Corr(x_i*y_i*x_j*y_j,  \\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2)=\\\\\n","   = \\frac{868*17*l/45+l(l-1)*8*868/90-868/15*(l*17/3+l(l-1)*8/6)}{\\sqrt{Var{[x_i^2*y_i^2]}\\cdot Var{[\\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2]}}}=0\n","$$\n","\n","\\\n","\n","Поэтому можем брять отдельно математическое ожидание от числителя и от знаменателя в дробях\n","\n","$$\n","  \\sum_{i=1}^l [\\frac{  E_{X^l} [x_i^2*y_i^2]}{ E_{X^l}[\\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2]}]=l*\\frac{1180/l}{l*17/3+l*(l-1)*8/6}=\\frac{1180*6}{34*l+l(l-1)8} \\; (1)\\\\\n","  2*\\sum_{i<j}[\\frac{E_{X^l}[x_i*x_j*y_i*y_j ]}{E_{X^l}[\\sum_{i=1}^l x_i^4+2*\\sum_{i<j} x_i^2*x_j^2]}]=l(l-1)*\\frac{868/15}{17l/3+l(l-1)*8/6}=\\frac{868*l(l-1)*2}{5*(34l+l(l-1)8)} \\; (2)\\\\\n","  (1)+(2)=\\frac{1180*30+1736*l*(l-1)}{5*(34l+l(l-1)8)}\n","$$\n","\n","Тогда разброс равняется:\n","\n","$$\n","  \\E_x[x^2]*(\\frac{1180*30+1736*l*(l-1)}{5*(34l+l(l-1)8)}-\\frac{27^2}{5^2})=\\frac{1}{3}\\cdot (\\frac{1180*30+1736*l*(l-1)}{(34l+l(l-1)8)}-\\frac{27^2}{5})\n","$$"]},{"cell_type":"markdown","metadata":{"id":"qkr0z6fwp4E8","colab_type":"text"},"source":["\n","### Задача 3. Взвешенное голосование (2 балла)\n","Рассмотрим задачу бинарной классификации, пусть у нас есть три алгоритма $b_1(x), b_2(x)$ и $b_3(x)$, каждый из которых ошибается с вероятностью $p$. Мы строим композицию взвешенным голосованием: алгоритмам присвоены значимости $w_1, w_2$ и $w_3$, и для вынесения вердикта суммируются значимости алгоритмов, проголосовавших за каждый из классов:\n","$$\n","a_0=\\sum_{i=1}^3w_i[b_i(x)=0], $$\n","$$\n","a_1=\\sum_{i=1}^3w_i[b_i(x)=1]. \\\\\n","$$\n","Объект $x$ относится к классу, для которого сумма оказалась максимальной. Например, если первые два алгоритма голосуют за класс $0$, а третий за класс $1$, то выбирается класс $0$, если $w_1+w_2>w_3$, и класс $1$ в противном случае. Какова вероятность ошибки такой композиции этих трех алгоритмов, если:\n","\n","* $w_1=0.3, w_2=0.4, w_3=0.3$;\n","* $w_1=0.2, w_2=0.5, w_3=0.2$?\n"]},{"cell_type":"markdown","metadata":{"id":"N_Dd-Uf5NDq0","colab_type":"text"},"source":["Рассмотрим сначала первый случай распределения весов:\n","\n","\\\n","\n","* $w_1=0.3, w_2=0.4, w_3=0.3$;\n","\n","\\\n","\n","В данном случае для ошибки необходимо, чтобы ошиблись любые два алгоритма или же ошиблись все три:\n","\n","Тогда суммарная вероятность ошибки получается как:\n","\n","$$\n","  C^2_3\\cdot p^2\\cdot (1-p)+p^3=3p^2-2p^3\n","$$\n","\n","\\\n","\n","Теперь ко второму случаю:\n","\n","* $w_1=0.2, w_2=0.5, w_3=0.2$\n","\n","Данное распределение весов отличается от первого тем, что если ошибутся первый и третий алгоритмы, а второй будет прав, то вся композиция будет верна. Поэтому для ошибки необходимо, чтобы был неправ второй алгоритм, ответы первого и третьего алгоритмов в сущности не влияют на результат голосования, поэтому ошибка будет происходить, только если ошибся второй алгоритм, а это происходит с вероятностью $p$."]},{"cell_type":"markdown","metadata":{"id":"wTKeYnW7p4FI","colab_type":"text"},"source":["### Задача 4. Разложение ошибки с помощью бутстрапа "]},{"cell_type":"markdown","metadata":{"id":"sR28cf_Yp4FL","colab_type":"text"},"source":["В этом задании вам предстоит воспользоваться возможностями bootstraping для оценки смещения и разброса алгоритмов машинного обучения. Делать мы это будем на данных boston:"]},{"cell_type":"code","metadata":{"id":"Y58dpVCSp4FN","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tClGAFip4FU","colab_type":"code","colab":{}},"source":["from sklearn.datasets import load_boston"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CS_nBlIFp4Fb","colab_type":"code","outputId":"cc9b109d-ad80-4803-b084-972b1ef8d22c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["boston = load_boston()\n","X = boston[\"data\"]\n","y = boston[\"target\"]\n","X.shape, y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((506, 13), (506,))"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"m2LiVwAjp4Fj","colab_type":"text"},"source":["#### Алгоритм оценки смещения и разброса алгоритма $a$\n","\n","1. Сгенерировать $s$ выборок $X_j$ методом бутстрапа.\n","\n","2. На каждой выборке $X_j$ обучить алгоритм $a_j$.\n","\n","3. Для каждой выборки $X_j$ определить множество объектов $T_j$, не вошедших в нее (out-of-bag). Вычислить предсказания алгоритма $a_j$ на объектах $T_j$.\n","\n","Поскольку у нас есть только один ответ для каждого объекта, мы будем считать шум равным 0, а $\\mathbb{E}[y|x]$ равным имеющемуся правильному ответу для объекта $x$.\n","\n","#### Итоговые оценки:\n","\n","* #### Смещение: \n","для одного объекта - квадрат разности среднего предсказания и правильного ответа. Среднее предсказание берется только по тем алгоритмам $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего смещения выполнить усреденение смещений по объектам.\n","* #### Разброс: \n","для одного объекта - выборочная дисперсия предсказаний алгоритмов $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего разброса выполнить усреденение разбросов по объектам.\n","* #### Ошибка $L$:\n","усреднить квадраты разностей предсказания и правильного ответа по всем выполненным предсказаниям для всех объектов.\n","\n","В результате должно получиться, что ошибка приблизительно равна сумме смещения и разброса!"]},{"cell_type":"markdown","metadata":{"id":"E1sGvAXIp4Fl","colab_type":"text"},"source":["* реализуйте описанный алгоритм. Обратите внимание, что если объект не вошел ни в одну из out-of-bag выборок, учитывать его в вычислении итоговых величин не нужно. (3 балла) \n","\n","* Оцените смещение, разброс и ошибку для трех алгоритмов с гиперпараметрами по умолчанию: линейная регрессия, решающее дерево, случайный лес.\n","\n","* Проанализируйте полученный результат. Согласуются ли полученные результаты с теми, что мы обсуждали на занятиях? (1 балл)"]},{"cell_type":"code","metadata":{"id":"6gb23RrI-wOc","colab_type":"code","outputId":"7591d4ac-60fb-49ff-c9be-d86777b9fb9c","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","\n","def bootstrap(data_x, data_y, model, s, l):\n","  a = np.ndarray(shape = (len(data_x),), dtype=list)\n","\n","  r = set(np.arange(len(data_x))) # множество всех присутствующих индексов\n","  out_of_bag_indices = set()    # множество индексов, которые были хотя бы у одного в out_of_back\n","\n","  for i in range(s):\n","    idx_in = np.random.randint(0,len(data_x)-1, l)# индексы для s-ой выборки\n","    idx_out = list(r^set(idx_in))                          # out of bag индексы\n","    out_of_bag_indices |= set(idx_out)\n","\n","    model.fit(data_x[idx_in], data_y[idx_in])\n","    predict_out = model.predict(data_x[idx_out])\n","    for p,i in zip(predict_out, idx_out):\n","      if(a[i]is None):\n","        a[i] = [p]\n","      else:\n","        a[i].append(p)\n","\n","  smesheniye = 0.0\n","  sigma = 0.0\n","  schet = 0\n","  error = 0.0\n","  for i in out_of_bag_indices:\n","    smesheniye+= 1.0/len(out_of_bag_indices)*(np.mean(a[i])-data_y[i])**2\n","    tmp = np.array(a[i])\n","    sigma += 1.0/(len(out_of_bag_indices)*len(tmp))*sum((tmp-tmp.mean())**2)\n","    schet+=len(tmp)\n","    error += sum((tmp-data_y[i])**2)\n","  error/=schet\n","  print(smesheniye, sigma, error)\n","  return smesheniye, sigma, error\n","\n","bootstrap(X,y, LinearRegression(), 10,250)\n","bootstrap(X,y, DecisionTreeRegressor(), 10,250)\n","bootstrap(X,y, RandomForestRegressor(), 10,250)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["23.593367393849658 1.4287185669591491 26.503589462954466\n","13.223328831677959 11.975589262305348 25.497431675996047\n","11.714775028197936 2.0259607037229834 13.56705380051897\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(11.714775028197936, 2.0259607037229834, 13.56705380051897)"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"markdown","metadata":{"id":"yDhIyzDcA2Sg","colab_type":"text"},"source":["У линейных моделей большое смещение из-за того, что они могут восстанавливать только линейные закономерности, но при этом низкий разброс из-за малого количества параметров, и ответы не сильно изменятся при изменении обучающей выборки, это и показываю результаты работы функции.\n","\n","У решающих деревьев смещение ниже, чем у линейных моделей, потому что они могут восстанавливать сложные нелинейные закономерности, но они сильно зависят от обучающей выборки, что приводит к увеличению разброса.\n","\n","При использовании случайного леса у нас смещение не сильно отличается от смещения одного дерева, а разброс в свою очередь уменьшается относительно одного базового дерева решения. Это и наблюдается в выводе функции."]},{"cell_type":"code","metadata":{"id":"DUpo5NNXFAn5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}